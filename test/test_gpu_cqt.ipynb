{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchaudio import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, fs = librosa.load(librosa.ex('trumpet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins_per_octave = 48\n",
    "num_octaves = 8\n",
    "cqt_fmin = 'A1'\n",
    "\n",
    "n_iter=32\n",
    "sr=44100\n",
    "hop_length=128\n",
    "fmin='A1'\n",
    "bins_per_octave=48\n",
    "tuning=0.0\n",
    "filter_scale=1\n",
    "norm=1\n",
    "sparsity=0.01\n",
    "window=\"hann\"\n",
    "scale=True\n",
    "pad_mode=\"reflect\"\n",
    "res_type=\"kaiser_fast\"\n",
    "dtype=None\n",
    "length=None\n",
    "momentum=0.99\n",
    "init=\"random\"\n",
    "random_state=None\n",
    "n_bins = num_octaves * bins_per_octave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16648/3554400944.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_inv_32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgriffinlim_cqt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins_per_octave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "y_inv_32 = librosa.griffinlim_cqt(C, sr=sr, n_iter=1, hop_length=128, bins_per_octave=48, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CQT magnitude\n",
    "C = librosa.cqt(y=s, sr=sr, hop_length= hop_length, bins_per_octave=bins_per_octave, n_bins=n_bins)\n",
    "# C = np.abs(C_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.empty(C.shape, dtype=np.complex64)\n",
    "\n",
    "# TODO change to torch.random later\n",
    "rng = np.random\n",
    "\n",
    "angles = np.empty(C.shape, dtype=np.complex64)\n",
    "# randomly initialize the phase\n",
    "angles[:] = np.exp(2j * np.pi * rng.rand(*C.shape))\n",
    "\n",
    "rebuilt = 0.0\n",
    "for _ in range(n_iter):\n",
    "    # Store the previous iterate\n",
    "    tprev = rebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is icqt part\n",
    "device = 'cuda:0'\n",
    "fmin = 32.70319566257483\n",
    "n_fft = 1024\n",
    "\n",
    "if not torch.is_tensor(C):\n",
    "    C = torch.from_numpy(C).to(device)\n",
    "\n",
    "# Get the top octave of frequencies\n",
    "n_bins = len(C)\n",
    "\n",
    "freqs = torch.from_numpy( np.array([4186.00904481, 4246.89594842, 4308.66847243, 4371.3394985, 4434.92209563, 4499.42952293, 4564.87523237, 4631.27287157, 4698.63628668, 4766.97952522, 4836.31683905, 4906.66268734, 4978.03173955, 5050.43887853, 5123.8992036 , 5198.42803371, 5274.04091061, 5350.75360212, 5428.58210544, 5507.5426504, 5587.65170293, 5668.92596846, 5751.38239541, 5835.0381787, 5919.91076339, 6006.01784824, 6093.37738948, 6182.00760451, 6271.92697571, 6363.15425427, 6455.70846416, 6549.60890603, 6644.87516128, 6741.52709612, 6839.58486572, 6939.06891843, 7040, 7142.39915796, 7246.28774597, 7351.68742829, 7458.62018429, 7567.10831304, 7677.17443796, 7788.84151154, 7902.1328201 , 8017.07198869, 8133.68298598, 8251.99012929], dtype=np.float64))\n",
    "freqs = freqs.to(device)\n",
    "\n",
    "n_filters = min(n_bins, bins_per_octave)\n",
    "\n",
    "lengths = torch.from_numpy(np.array( [724.29368857, 713.90963383, 703.67445322, 693.58601236, 683.64220748, 673.84096495, 664.18024089, 654.65802071, 645.2723187 , 636.02117765, 626.90266836, 617.91488933, 609.05596631, 600.3240519 , 591.71732522, 583.23399147, 574.87228158, 566.63045188, 558.50678364, 550.49958283, 542.60717966, 534.82792831, 527.16020654, 519.60241537, 512.15297876, 504.81034324, 497.57297762, 490.43937268, 483.40804081, 476.47751576, 469.64635226, 462.9131258, 456.27643227, 449.73488769, 443.28712794, 436.93180844, 430.6676039 , 424.49320801, 418.40733321, 412.40871038, 406.49608862, 400.66823495, 394.92393405, 389.26198806, 383.68121626, 378.18045488, 372.75855682, 367.41439143], dtype=np.float64) )\n",
    "lengths = lengths.to(device)\n",
    "\n",
    "if hop_length > min(lengths):\n",
    "    warnings.warn(\n",
    "        \"hop_length={} exceeds minimum CQT filter length={:.3f}.\\n\"\n",
    "        \"This will probably cause unpleasant acoustic artifacts. \"\n",
    "        \"Consider decreasing your hop length or increasing the \"\n",
    "        \"frequency resolution of your CQT.\".format(hop_length, min(lengths))\n",
    "    )\n",
    "\n",
    "if length is not None:\n",
    "    n_frames = int(np.ceil((length + max(lengths)) / hop_length))\n",
    "    C = C[:, :n_frames]\n",
    "\n",
    "# The basis gets renormalized by the effective window length above;\n",
    "# This step undoes that\n",
    "\n",
    "# This step conjugate-transposes the filter\n",
    "inv_basis = torch.zeros((513,48), dtype=torch.complex64, device=device)\n",
    "\n",
    "# How many octaves do we have?\n",
    "n_octaves = int(np.ceil(float(n_bins) / bins_per_octave))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02609286],\n",
       "       [0.02590514],\n",
       "       [0.02571877],\n",
       "       [0.02553374],\n",
       "       [0.02535005],\n",
       "       [0.02516767],\n",
       "       [0.02498661],\n",
       "       [0.02480685],\n",
       "       [0.02462838],\n",
       "       [0.0244512 ],\n",
       "       [0.02427529],\n",
       "       [0.02410064],\n",
       "       [0.02392726],\n",
       "       [0.02375512],\n",
       "       [0.02358422],\n",
       "       [0.02341455],\n",
       "       [0.02324609],\n",
       "       [0.02307886],\n",
       "       [0.02291282],\n",
       "       [0.02274798],\n",
       "       [0.02258432],\n",
       "       [0.02242185],\n",
       "       [0.02226054],\n",
       "       [0.02210039],\n",
       "       [0.02194139],\n",
       "       [0.02178354],\n",
       "       [0.02162682],\n",
       "       [0.02147123],\n",
       "       [0.02131676],\n",
       "       [0.0211634 ],\n",
       "       [0.02101115],\n",
       "       [0.02085999],\n",
       "       [0.02070992],\n",
       "       [0.02056092],\n",
       "       [0.020413  ],\n",
       "       [0.02026614],\n",
       "       [0.02012034],\n",
       "       [0.01997559],\n",
       "       [0.01983188],\n",
       "       [0.01968921],\n",
       "       [0.01954756],\n",
       "       [0.01940693],\n",
       "       [0.01926731],\n",
       "       [0.01912869],\n",
       "       [0.01899108],\n",
       "       [0.01885445],\n",
       "       [0.01871881]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[713.9096],\n",
       "        [703.6745],\n",
       "        [693.5860],\n",
       "        [683.6422],\n",
       "        [673.8410],\n",
       "        [664.1802],\n",
       "        [654.6580],\n",
       "        [645.2723],\n",
       "        [636.0212],\n",
       "        [626.9027],\n",
       "        [617.9149],\n",
       "        [609.0560],\n",
       "        [600.3241],\n",
       "        [591.7173],\n",
       "        [583.2340],\n",
       "        [574.8723],\n",
       "        [566.6305],\n",
       "        [558.5068],\n",
       "        [550.4996],\n",
       "        [542.6072],\n",
       "        [534.8279],\n",
       "        [527.1602],\n",
       "        [519.6024],\n",
       "        [512.1530],\n",
       "        [504.8103],\n",
       "        [497.5730],\n",
       "        [490.4394],\n",
       "        [483.4080],\n",
       "        [476.4775],\n",
       "        [469.6464],\n",
       "        [462.9131],\n",
       "        [456.2764],\n",
       "        [449.7349],\n",
       "        [443.2871],\n",
       "        [436.9318],\n",
       "        [430.6676],\n",
       "        [424.4932],\n",
       "        [418.4073],\n",
       "        [412.4087],\n",
       "        [406.4961],\n",
       "        [400.6682],\n",
       "        [394.9239],\n",
       "        [389.2620],\n",
       "        [383.6812],\n",
       "        [378.1805],\n",
       "        [372.7586],\n",
       "        [367.4144]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths[-C_oct.shape[0] :].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_oct = C_oct.cpu().numpy()\n",
    "lengths_test = lengths.cpu().numpy()\n",
    "C_scale = np.sqrt(lengths_test[-C_oct.shape[0] :, np.newaxis]) / n_fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(D_oct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (459) must match the size of tensor b (1836) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19712/2799066455.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_oct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my_oct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (459) must match the size of tensor b (1836) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "y = None\n",
    "for octave in range(n_octaves - 1, -1, -1):\n",
    "    slice_ = slice(\n",
    "        -(octave + 1) * bins_per_octave - 1, -(octave) * bins_per_octave - 1\n",
    "    )\n",
    "\n",
    "    # Slice this octave\n",
    "    C_oct = C[slice_]\n",
    "    inv_oct = inv_basis[:, -C_oct.shape[0] :]\n",
    "\n",
    "    oct_hop = hop_length // 2 ** octave\n",
    "\n",
    "    # Apply energy corrections\n",
    "    if scale:\n",
    "        C_scale = torch.sqrt( lengths[-C_oct.shape[0] :].unsqueeze(1) ) / n_fft\n",
    "    \n",
    "    else:\n",
    "        C_scale = (\n",
    "            lengths[-C_oct.shape[0] :, np.newaxis] * np.sqrt(2 ** octave) / n_fft\n",
    "        )\n",
    "\n",
    "    # Inverse-project the basis for each octave\n",
    "    C_div = C_oct / C_scale\n",
    "    D_oct = torch.matmul(inv_oct, C_div.type(torch.complex64))\n",
    "\n",
    "    # Inverse-STFT that response\n",
    "    y_oct = torch.istft(D_oct, hop_length=oct_hop, n_fft=n_fft)\n",
    "\n",
    "    # Up-sample that octave\n",
    "    if y is None:\n",
    "        y = y_oct\n",
    "    else:\n",
    "        # Up-sample the previous buffer and add in the new one\n",
    "        # Scipy-resampling is fast here, since it's a power-of-two relation\n",
    "        transform = transforms.Resample(sr, sr /2).to(device)\n",
    "        y = transform(y)\n",
    "\n",
    "        y[: len(y_oct)] += y_oct\n",
    "\n",
    "if length:\n",
    "    y = util.fix_length(y, length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1836])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_inv_basis = torch.zeros((513,48), dtype=torch.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_inv_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a86aa82118571f9d8f7fa781846b8943f2f75063e6819825593750af2688f4f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pt110': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
